{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# –ó–ê–ì–†–£–ó–ö–ê –ì–†–ê–§–ê –ò–ó PICKLE\n",
    "\n",
    "def load_graph_pickle(pickle_file):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥—Ä–∞—Ñ –∏–∑ pickle —Ñ–∞–π–ª–∞\"\"\"\n",
    "    print(f\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ {pickle_file}...\")\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        G = pickle.load(f)\n",
    "    print(f\"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {G.number_of_nodes()} —É–∑–ª–æ–≤, {G.number_of_edges()} —Ä—ë–±–µ—Ä\")\n",
    "    return G\n",
    "\n",
    "\n",
    "# 1. –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–´–ô –†–ê–°–ß–ï–¢: –ò—Å—Ö–æ–¥–Ω—ã–µ –∫—Ä–∞—Ç—á–∞–π—à–∏–µ –ø—É—Ç–∏ d_ij\n",
    "\n",
    "def calculate_initial_distances(graph, od_pairs_file, output_file='initial_distances.csv'):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–µ –∫—Ä–∞—Ç—á–∞–π—à–µ–µ –≤—Ä–µ–º—è –≤ –ø—É—Ç–∏ –¥–ª—è –≤—Å–µ—Ö O-D –ø–∞—Ä.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä –®–ê–ì 1: –†–ê–°–ß–ï–¢ –ò–°–•–û–î–ù–´–• –†–ê–°–°–¢–û–Ø–ù–ò–ô\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(f\"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ O-D –ø–∞—Ä –∏–∑ {od_pairs_file}...\")\n",
    "    od_pairs = pd.read_csv(od_pairs_file)\n",
    "\n",
    "    results = []\n",
    "    print(f\"üìê –†–∞—Å—á–µ—Ç –∫—Ä–∞—Ç—á–∞–π—à–∏—Ö –ø—É—Ç–µ–π –¥–ª—è {len(od_pairs)} –ø–∞—Ä...\")\n",
    "\n",
    "    for idx, row in tqdm(od_pairs.iterrows(), total=len(od_pairs), desc=\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä\"):\n",
    "        origin = row['node_id_origin']\n",
    "        dest = row['node_id_dest']\n",
    "\n",
    "        try:\n",
    "            # –ö—Ä–∞—Ç—á–∞–π—à–∏–π –ø—É—Ç—å –ø–æ –≤–µ—Å—É travel_time\n",
    "            distance = nx.shortest_path_length(graph, origin, dest, weight='travel_time')\n",
    "            results.append({\n",
    "                'origin': origin,\n",
    "                'dest': dest,\n",
    "                'distance_original': distance\n",
    "            })\n",
    "        except nx.NetworkXNoPath:\n",
    "            # –ï—Å–ª–∏ –ø—É—Ç–∏ –Ω–µ—Ç, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ = –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å\n",
    "            results.append({\n",
    "                'origin': origin,\n",
    "                'dest': dest,\n",
    "                'distance_original': np.inf\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    valid_distances = df[df['distance_original'] != np.inf]['distance_original']\n",
    "    print(f\"\\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}\")\n",
    "    print(f\"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "    print(f\"   - –í—Å–µ–≥–æ –ø–∞—Ä: {len(df)}\")\n",
    "    print(f\"   - –°–≤—è–∑–Ω—ã—Ö –ø–∞—Ä: {len(valid_distances)}\")\n",
    "    print(f\"   - –ù–µ—Å–≤—è–∑–Ω—ã—Ö –ø–∞—Ä: {len(df) - len(valid_distances)}\")\n",
    "    print(f\"   - –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {valid_distances.mean():.2f} –º–∏–Ω\")\n",
    "    print(f\"   - –ú–µ–¥–∏–∞–Ω–∞: {valid_distances.median():.2f} –º–∏–Ω\")\n",
    "    print(f\"   - –ú–∞–∫—Å: {valid_distances.max():.2f} –º–∏–Ω\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 2. –†–ê–°–ß–ï–¢ –ö–†–ò–¢–ò–ß–ù–û–°–¢–ò –†–ï–ë–†–ê (W_e) - STRETCH FACTOR\n",
    "def calculate_edge_criticality(graph, od_pairs_df, demand_dict=None,\n",
    "                                    output_file=\"criticality_scores.csv\",\n",
    "                                    checkpoint_interval=100):\n",
    "    \"\"\"\n",
    "    –ë—ã—Å—Ç—Ä—ã–π —Ä–∞—Å—á—ë—Ç –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ —Ä–µ–±—Ä–∞ —á–µ—Ä–µ–∑ –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ SPT –¥–µ—Ä–µ–≤—å—è.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚ö° –ë–´–°–¢–†–´–ô –®–ê–ì 2: –†–ê–°–ß–Å–¢ –ö–†–ò–¢–ò–ß–ù–û–°–¢–ò –†–Å–ë–ï–† (W_e)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    edges = list(graph.edges(keys=True))\n",
    "\n",
    "    # --- 1. –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–≤—è–∑–Ω—ã–µ –ø–∞—Ä—ã\n",
    "    valid_od = od_pairs_df[od_pairs_df[\"distance_original\"] != np.inf]\n",
    "\n",
    "    # --- 2. –°–ø—Ä–æ—Å\n",
    "    if demand_dict is None:\n",
    "        demand_dict = {(row[\"origin\"], row[\"dest\"]): 1\n",
    "                       for _, row in valid_od.iterrows()}\n",
    "\n",
    "    # --- 3. –£–∑–ª—ã, –æ—Ç –∫–æ—Ç–æ—Ä—ã—Ö —Å—á–∏—Ç–∞–µ–º SPT\n",
    "    sources = valid_od[\"origin\"].unique()\n",
    "\n",
    "    print(f\"üß† –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ SPT –æ—Ç {len(sources)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...\")\n",
    "\n",
    "    # SPT:\n",
    "    # dist[source][node] = –¥–∏—Å—Ç–∞–Ω—Ü–∏—è\n",
    "    # parent[source][node] = –ø—Ä–µ–¥—ã–¥—É—â–∏–π —É–∑–µ–ª –Ω–∞ –∫—Ä–∞—Ç—á–∞–π—à–µ–º –ø—É—Ç–∏\n",
    "    dist = {}\n",
    "    parent = {}\n",
    "\n",
    "    for s in tqdm(sources, desc=\"SPT trees\"):\n",
    "        lengths, paths = nx.single_source_dijkstra(graph, s, weight=\"travel_time\")\n",
    "\n",
    "        dist[s] = lengths\n",
    "\n",
    "        # —Å—Ç—Ä–æ–∏–º parent-—Ç–∞–±–ª–∏—Ü—É\n",
    "        p = {}\n",
    "        for t, path in paths.items():\n",
    "            if len(path) >= 2:\n",
    "                p[t] = path[-2]  # —Ä–æ–¥–∏—Ç–µ–ª—å\n",
    "        parent[s] = p\n",
    "\n",
    "    print(\"‚úì SPT –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã\\n\")\n",
    "\n",
    "    # --- 4. –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ —Ä–µ–±—Ä–æ (u,v) –Ω–∞ –ø—É—Ç–∏ s‚Üít\n",
    "    def edge_on_path(s, t, u, v):\n",
    "        curr = t\n",
    "        while curr != s and curr in parent[s]:\n",
    "            p = parent[s][curr]\n",
    "            if (p == u and curr == v) or (p == v and curr == u):\n",
    "                return True\n",
    "            curr = p\n",
    "        return False\n",
    "\n",
    "    criticality = []\n",
    "    print(f\"üîç –†–∞—Å—á—ë—Ç –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ {len(edges)} —Ä—ë–±–µ—Ä...\\n\")\n",
    "\n",
    "    for idx, (u, v, key) in enumerate(tqdm(edges, desc=\"Edges\")):\n",
    "        W = 0\n",
    "\n",
    "        # --- –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –ø–∞—Ä—ã\n",
    "        for _, row in valid_od.iterrows():\n",
    "            s = row[\"origin\"]\n",
    "            t = row[\"dest\"]\n",
    "            d_orig = row[\"distance_original\"]\n",
    "\n",
    "            # –µ—Å–ª–∏ –ø—É—Ç—å –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–±—Ä–æ ‚Äî –≤–∫–ª–∞–¥ 0\n",
    "            if not edge_on_path(s, t, u, v):\n",
    "                continue\n",
    "\n",
    "            # –ø–µ—Ä–µ—Å—á—ë—Ç d_new\n",
    "            try:\n",
    "                # –£–±–∏—Ä–∞–µ–º —Ä–µ–±—Ä–æ (–±—ã—Å—Ç—Ä–µ–µ, —á–µ–º –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ!)\n",
    "                graph.remove_edge(u, v, key)\n",
    "                d_new = nx.shortest_path_length(graph, s, t, weight=\"travel_time\")\n",
    "                graph.add_edge(u, v, key)  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ\n",
    "\n",
    "                stretch = max(0, (d_new - d_orig) / d_orig)\n",
    "\n",
    "            except nx.NetworkXNoPath:\n",
    "                # –µ—Å–ª–∏ –ø—É—Ç—å –∏—Å—á–µ–∑\n",
    "                stretch = 10.0\n",
    "\n",
    "            demand = demand_dict.get((s, t), 1)\n",
    "            W += stretch * demand\n",
    "\n",
    "        criticality.append({\n",
    "            \"edge_u\": u,\n",
    "            \"edge_v\": v,\n",
    "            \"edge_key\": key,\n",
    "            \"W_e\": W\n",
    "        })\n",
    "\n",
    "        if (idx + 1) % checkpoint_interval == 0:\n",
    "            pd.DataFrame(criticality).to_csv(\"checkpoint_\" + output_file, index=False)\n",
    "\n",
    "    df = pd.DataFrame(criticality).sort_values(\"W_e\", ascending=False)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\"\\n‚úì –ì–æ—Ç–æ–≤–æ! –ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å –ø–æ—Å—á–∏—Ç–∞–Ω–∞.\")\n",
    "    print(df.head(10).to_string())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 3. –ú–ï–¢–†–ò–ö–ò: LCC –∏ GLOBAL EFFICIENCY\n",
    "\n",
    "def calculate_lcc(graph):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∫—Ä—É–ø–Ω–µ–π—à–µ–π —Å–≤—è–∑–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (LCC).\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–ª—é —É–∑–ª–æ–≤ –≤ LCC –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ —É–∑–ª–æ–≤.\n",
    "    \"\"\"\n",
    "    if graph.number_of_nodes() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # –î–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º weakly connected\n",
    "    if graph.is_directed():\n",
    "        largest_cc = max(nx.weakly_connected_components(graph), key=len)\n",
    "    else:\n",
    "        largest_cc = max(nx.connected_components(graph), key=len)\n",
    "\n",
    "    return len(largest_cc) / graph.number_of_nodes()\n",
    "\n",
    "\n",
    "def calculate_global_efficiency(graph, sample_size=None):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (E).\n",
    "\n",
    "    E = 1 / (N*(N-1)) * Œ£ (1 / d_ij)\n",
    "\n",
    "    Args:\n",
    "        graph: NetworkX –≥—Ä–∞—Ñ\n",
    "        sample_size: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—ã–±–æ—Ä–∫—É —É–∑–ª–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "    \"\"\"\n",
    "    nodes = list(graph.nodes())\n",
    "    N = len(nodes)\n",
    "\n",
    "    if N <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    # –î–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä–∞—Ñ–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±–æ—Ä–∫—É\n",
    "    if sample_size and N > sample_size:\n",
    "        nodes = np.random.choice(nodes, sample_size, replace=False)\n",
    "        N = len(nodes)\n",
    "\n",
    "    total_inv_distance = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        # –ö—Ä–∞—Ç—á–∞–π—à–∏–µ –ø—É—Ç–∏ –æ—Ç —É–∑–ª–∞ i –∫–æ –≤—Å–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–º\n",
    "        try:\n",
    "            lengths = nx.single_source_dijkstra_path_length(\n",
    "                graph, nodes[i], weight='travel_time'\n",
    "            )\n",
    "\n",
    "            for j in range(i + 1, N):\n",
    "                if nodes[j] in lengths:\n",
    "                    d_ij = lengths[nodes[j]]\n",
    "                    if d_ij > 0:\n",
    "                        total_inv_distance += 1.0 / d_ij\n",
    "                        count += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if count == 0:\n",
    "        return 0.0\n",
    "\n",
    "    efficiency = total_inv_distance / (N * (N - 1))\n",
    "    return efficiency\n",
    "\n",
    "\n",
    "# 4. –°–ò–ú–£–õ–Ø–¶–ò–Ø: –¶–ï–õ–ï–í–ê–Ø –ê–¢–ê–ö–ê (Targeted Attack)\n",
    "\n",
    "def simulate_targeted_attack(graph, criticality_df, steps=20, efficiency_sample=500):\n",
    "    \"\"\"\n",
    "    –°–∏–º—É–ª–∏—Ä—É–µ—Ç —Ü–µ–ª–µ–≤—É—é –∞—Ç–∞–∫—É: —É–¥–∞–ª—è–µ—Ç —Ä–µ–±—Ä–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "    Args:\n",
    "        graph: –∏—Å—Ö–æ–¥–Ω—ã–π –≥—Ä–∞—Ñ\n",
    "        criticality_df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ edge_u, edge_v, edge_key, W_e\n",
    "        steps: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (–ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–∏—è)\n",
    "        efficiency_sample: —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ Efficiency\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ –®–ê–ì 3: –°–ò–ú–£–õ–Ø–¶–ò–Ø –¶–ï–õ–ï–í–û–ô –ê–¢–ê–ö–ò\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    G = graph.copy()\n",
    "    total_edges = G.number_of_edges()\n",
    "    edges_to_remove = criticality_df[['edge_u', 'edge_v', 'edge_key']].values\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
    "    print(\"üìä –†–∞—Å—á–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫...\")\n",
    "    lcc_0 = calculate_lcc(G)\n",
    "    eff_0 = calculate_global_efficiency(G, sample_size=efficiency_sample)\n",
    "    results.append({\n",
    "        'fraction_removed': 0.0,\n",
    "        'strategy': 'Targeted',\n",
    "        'metric_type': 'LCC',\n",
    "        'value': lcc_0\n",
    "    })\n",
    "    results.append({\n",
    "        'fraction_removed': 0.0,\n",
    "        'strategy': 'Targeted',\n",
    "        'metric_type': 'Efficiency',\n",
    "        'value': eff_0\n",
    "    })\n",
    "\n",
    "    print(f\"   –ò—Å—Ö–æ–¥–Ω–∞—è LCC: {lcc_0:.4f}\")\n",
    "    print(f\"   –ò—Å—Ö–æ–¥–Ω–∞—è Efficiency: {eff_0:.6f}\")\n",
    "    print(f\"\\nüî® –ù–∞—á–∏–Ω–∞—é —É–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–±–µ—Ä –ø–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏...\")\n",
    "    print(f\"   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {steps}\")\n",
    "    print(f\"   –†–µ–±–µ—Ä –Ω–∞ —à–∞–≥: ~{total_edges // steps}\")\n",
    "\n",
    "    # –£–¥–∞–ª—è–µ–º —Ä–µ–±—Ä–∞ —à–∞–≥–∞–º–∏\n",
    "    step_size = len(edges_to_remove) // steps\n",
    "\n",
    "    for step in tqdm(range(1, steps + 1), desc=\"–¶–µ–ª–µ–≤–∞—è –∞—Ç–∞–∫–∞\"):\n",
    "        # –£–¥–∞–ª—è–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø–æ—Ä—Ü–∏—é —Ä–µ–±–µ—Ä\n",
    "        start_idx = (step - 1) * step_size\n",
    "        end_idx = min(step * step_size, len(edges_to_remove))\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            u, v, key = edges_to_remove[i]\n",
    "            if G.has_edge(u, v, key):\n",
    "                G.remove_edge(u, v, key)\n",
    "\n",
    "        fraction = step / steps\n",
    "\n",
    "        # –ò–∑–º–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        lcc = calculate_lcc(G)\n",
    "        eff = calculate_global_efficiency(G, sample_size=efficiency_sample)\n",
    "\n",
    "        results.append({\n",
    "            'fraction_removed': fraction,\n",
    "            'strategy': 'Targeted',\n",
    "            'metric_type': 'LCC',\n",
    "            'value': lcc\n",
    "        })\n",
    "        results.append({\n",
    "            'fraction_removed': fraction,\n",
    "            'strategy': 'Targeted',\n",
    "            'metric_type': 'Efficiency',\n",
    "            'value': eff\n",
    "        })\n",
    "\n",
    "        if step % 5 == 0 or step == steps:\n",
    "            print(f\"   –®–∞–≥ {step}/{steps} ({fraction*100:.0f}%): LCC={lcc:.4f}, Eff={eff:.6f}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ –¶–µ–ª–µ–≤–∞—è –∞—Ç–∞–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# 5. –°–ò–ú–£–õ–Ø–¶–ò–Ø: –°–õ–£–ß–ê–ô–ù–´–ô –û–¢–ö–ê–ó (Random Failure)\n",
    "\n",
    "def simulate_random_failure(graph, steps=20, runs=50, efficiency_sample=500):\n",
    "    \"\"\"\n",
    "    –°–∏–º—É–ª–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –æ—Ç–∫–∞–∑: —É–¥–∞–ª—è–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ —Ä–µ–±—Ä–∞.\n",
    "    –ü–æ–≤—Ç–æ—Ä—è–µ—Ç runs —Ä–∞–∑ –∏ —É—Å—Ä–µ–¥–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
    "\n",
    "    Args:\n",
    "        graph: –∏—Å—Ö–æ–¥–Ω—ã–π –≥—Ä–∞—Ñ\n",
    "        steps: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (–ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–∏—è)\n",
    "        runs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è\n",
    "        efficiency_sample: —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ Efficiency\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üé≤ –®–ê–ì 4: –°–ò–ú–£–õ–Ø–¶–ò–Ø –°–õ–£–ß–ê–ô–ù–û–ì–û –û–¢–ö–ê–ó–ê\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–æ–Ω–æ–≤: {runs}\")\n",
    "    print(f\"   –®–∞–≥–æ–≤ –Ω–∞ –ø—Ä–æ–≥–æ–Ω: {steps}\")\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for run in tqdm(range(runs), desc=\"–ü—Ä–æ–≥–æ–Ω—ã\"):\n",
    "        G = graph.copy()\n",
    "        total_edges = G.number_of_edges()\n",
    "        all_edges = list(G.edges(keys=True))\n",
    "\n",
    "        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Ä–µ–±—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º\n",
    "        np.random.shuffle(all_edges)\n",
    "\n",
    "        run_results = []\n",
    "\n",
    "        # –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
    "        lcc_0 = calculate_lcc(G)\n",
    "        eff_0 = calculate_global_efficiency(G, sample_size=efficiency_sample)\n",
    "        run_results.append({\n",
    "            'fraction_removed': 0.0,\n",
    "            'run': run,\n",
    "            'LCC': lcc_0,\n",
    "            'Efficiency': eff_0\n",
    "        })\n",
    "\n",
    "        # –£–¥–∞–ª—è–µ–º —Ä–µ–±—Ä–∞ —à–∞–≥–∞–º–∏\n",
    "        step_size = total_edges // steps\n",
    "\n",
    "        for step in range(1, steps + 1):\n",
    "            start_idx = (step - 1) * step_size\n",
    "            end_idx = min(step * step_size, len(all_edges))\n",
    "\n",
    "            for i in range(start_idx, end_idx):\n",
    "                u, v, key = all_edges[i]\n",
    "                if G.has_edge(u, v, key):\n",
    "                    G.remove_edge(u, v, key)\n",
    "\n",
    "            fraction = step / steps\n",
    "            lcc = calculate_lcc(G)\n",
    "            eff = calculate_global_efficiency(G, sample_size=efficiency_sample)\n",
    "\n",
    "            run_results.append({\n",
    "                'fraction_removed': fraction,\n",
    "                'run': run,\n",
    "                'LCC': lcc,\n",
    "                'Efficiency': eff\n",
    "            })\n",
    "\n",
    "        all_results.extend(run_results)\n",
    "\n",
    "    # –£—Å—Ä–µ–¥–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –≤—Å–µ–º –ø—Ä–æ–≥–æ–Ω–∞–º\n",
    "    df_all = pd.DataFrame(all_results)\n",
    "    df_avg = df_all.groupby('fraction_removed').agg({\n",
    "        'LCC': 'mean',\n",
    "        'Efficiency': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç\n",
    "    results = []\n",
    "    for _, row in df_avg.iterrows():\n",
    "        results.append({\n",
    "            'fraction_removed': row['fraction_removed'],\n",
    "            'strategy': 'Random',\n",
    "            'metric_type': 'LCC',\n",
    "            'value': row['LCC']\n",
    "        })\n",
    "        results.append({\n",
    "            'fraction_removed': row['fraction_removed'],\n",
    "            'strategy': 'Random',\n",
    "            'metric_type': 'Efficiency',\n",
    "            'value': row['Efficiency']\n",
    "        })\n",
    "\n",
    "    print(f\"\\n‚úÖ –°–ª—É—á–∞–π–Ω—ã–π –æ—Ç–∫–∞–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –£—Å—Ä–µ–¥–Ω–µ–Ω–æ {runs} –ø—Ä–æ–≥–æ–Ω–æ–≤\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# 6. –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ü–û–õ–ù–´–ô –ü–ê–ô–ü–õ–ê–ô–ù\n",
    "\n",
    "def main_pipeline(graph_name='zmr', data_dir='map_data', output_dir='results'):\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–∫–æ–ª—è—Ü–∏–∏.\n",
    "\n",
    "    Args:\n",
    "        graph_name: –∏–º—è –≥—Ä–∞—Ñ–∞ ('moscow', 'sao', 'zmr')\n",
    "        data_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç –û–ª–µ–≥–∞\n",
    "        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üöÄ –°–¢–ê–†–¢ –ê–ù–ê–õ–ò–ó–ê –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–û–ô –£–°–¢–û–ô–ß–ò–í–û–°–¢–ò: {graph_name.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º\n",
    "    graph_file = os.path.join(data_dir, f'{graph_name}.pkl')\n",
    "    od_pairs_file = os.path.join(data_dir, f'{graph_name}_od_pairs.csv')\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞\n",
    "    G = load_graph_pickle(graph_file)\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç—Ç–æ–≥–æ –≥—Ä–∞—Ñ–∞\n",
    "    graph_output_dir = os.path.join(output_dir, graph_name)\n",
    "    os.makedirs(graph_output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. –ò—Å—Ö–æ–¥–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è\n",
    "    initial_dist_file = os.path.join(graph_output_dir, 'initial_distances.csv')\n",
    "    if not os.path.exists(initial_dist_file):\n",
    "        od_df = calculate_initial_distances(G, od_pairs_file, initial_dist_file)\n",
    "    else:\n",
    "        print(f\"\\n‚úì –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π {initial_dist_file}, –∑–∞–≥—Ä—É–∂–∞—é...\")\n",
    "        od_df = pd.read_csv(initial_dist_file)\n",
    "        print(f\"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(od_df)} O-D –ø–∞—Ä\")\n",
    "\n",
    "    # 2. –ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–±–µ—Ä\n",
    "    criticality_file = os.path.join(graph_output_dir, 'criticality_scores.csv')\n",
    "    if not os.path.exists(criticality_file):\n",
    "        crit_df = calculate_edge_criticality(G, od_df, output_file=criticality_file)\n",
    "    else:\n",
    "        print(f\"\\n‚úì –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π {criticality_file}, –∑–∞–≥—Ä—É–∂–∞—é...\")\n",
    "        crit_df = pd.read_csv(criticality_file)\n",
    "        print(f\"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–µ–π –¥–ª—è {len(crit_df)} —Ä–µ–±–µ—Ä\")\n",
    "\n",
    "    # 3. –¶–µ–ª–µ–≤–∞—è –∞—Ç–∞–∫–∞\n",
    "    results_targeted = simulate_targeted_attack(G, crit_df, steps=20, efficiency_sample=500)\n",
    "\n",
    "    # 4. –°–ª—É—á–∞–π–Ω—ã–π –æ—Ç–∫–∞–∑\n",
    "    results_random = simulate_random_failure(G, steps=20, runs=50, efficiency_sample=500)\n",
    "\n",
    "    # 5. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\")\n",
    "    print(\"=\"*80)\n",
    "    final_results = pd.concat([results_targeted, results_random], ignore_index=True)\n",
    "\n",
    "    output_file = os.path.join(graph_output_dir, 'percolation_results.csv')\n",
    "    final_results.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}\")\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "    stats_file = os.path.join(graph_output_dir, 'summary.txt')\n",
    "    with open(stats_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"–ì—Ä–∞—Ñ: {graph_name}\\n\")\n",
    "        f.write(f\"–£–∑–ª–æ–≤: {G.number_of_nodes()}\\n\")\n",
    "        f.write(f\"–†–µ–±–µ—Ä: {G.number_of_edges()}\\n\")\n",
    "        f.write(f\"O-D –ø–∞—Ä: {len(od_df)}\\n\")\n",
    "        f.write(f\"\\n–ò—Å—Ö–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:\\n\")\n",
    "        f.write(f\"LCC: {results_targeted[results_targeted['fraction_removed']==0]['value'].iloc[0]:.4f}\\n\")\n",
    "        f.write(f\"Efficiency: {results_targeted[results_targeted['fraction_removed']==0]['value'].iloc[1]:.6f}\\n\")\n",
    "\n",
    "    print(f\"üìÑ –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {stats_file}\")\n",
    "\n",
    "    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫\n",
    "    plot_results(final_results, graph_output_dir, graph_name)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –î–õ–Ø {graph_name.upper()}!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return final_results\n",
    "\n",
    "\n",
    "# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø\n",
    "\n",
    "def plot_results(results, output_dir, graph_name):\n",
    "    \"\"\"–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –ø–µ—Ä–∫–æ–ª—è—Ü–∏–∏\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(\"\\nüìà –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # LCC\n",
    "    for strategy in ['Targeted', 'Random']:\n",
    "        data = results[(results['strategy'] == strategy) &\n",
    "                      (results['metric_type'] == 'LCC')]\n",
    "        ax1.plot(data['fraction_removed'], data['value'],\n",
    "                marker='o', label=strategy, linewidth=2, markersize=6)\n",
    "\n",
    "    ax1.set_xlabel('–î–æ–ª—è —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ä–µ–±–µ—Ä', fontsize=12)\n",
    "    ax1.set_ylabel('LCC (—Ä–∞–∑–º–µ—Ä –∫—Ä—É–ø–Ω–µ–π—à–µ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)', fontsize=12)\n",
    "    ax1.set_title(f'–ü–µ—Ä–∫–æ–ª—è—Ü–∏—è: LCC ({graph_name})', fontsize=14, weight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(alpha=0.3, linestyle='--')\n",
    "    ax1.set_xlim(-0.05, 1.05)\n",
    "    ax1.set_ylim(-0.05, 1.05)\n",
    "\n",
    "    # Efficiency\n",
    "    for strategy in ['Targeted', 'Random']:\n",
    "        data = results[(results['strategy'] == strategy) &\n",
    "                      (results['metric_type'] == 'Efficiency')]\n",
    "        ax2.plot(data['fraction_removed'], data['value'],\n",
    "                marker='s', label=strategy, linewidth=2, markersize=6)\n",
    "\n",
    "    ax2.set_xlabel('–î–æ–ª—è —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ä–µ–±–µ—Ä', fontsize=12)\n",
    "    ax2.set_ylabel('–ì–ª–æ–±–∞–ª—å–Ω–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (E)', fontsize=12)\n",
    "    ax2.set_title(f'–ü–µ—Ä–∫–æ–ª—è—Ü–∏—è: Efficiency ({graph_name})', fontsize=14, weight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(alpha=0.3, linestyle='--')\n",
    "    ax2.set_xlim(-0.05, 1.05)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_file = os.path.join(output_dir, 'percolation_plot.png')\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   ‚úì –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_file}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ –í—ã–±—Ä–∞–Ω –≥—Ä–∞—Ñ: ZMR\n",
      "üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏: map_data\n",
      "üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: results\n",
      "\n",
      "================================================================================\n",
      "üöÄ –°–¢–ê–†–¢ –ê–ù–ê–õ–ò–ó–ê –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–û–ô –£–°–¢–û–ô–ß–ò–í–û–°–¢–ò: ZMR\n",
      "================================================================================\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ map_data/zmr.pkl...\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: 178 —É–∑–ª–æ–≤, 372 —Ä—ë–±–µ—Ä\n",
      "\n",
      "‚úì –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π results/zmr/initial_distances.csv, –∑–∞–≥—Ä—É–∂–∞—é...\n",
      "   –ó–∞–≥—Ä—É–∂–µ–Ω–æ 5000 O-D –ø–∞—Ä\n",
      "\n",
      "================================================================================\n",
      "‚ö° –ë–´–°–¢–†–´–ô –®–ê–ì 2: –†–ê–°–ß–Å–¢ –ö–†–ò–¢–ò–ß–ù–û–°–¢–ò –†–Å–ë–ï–† (W_e)\n",
      "================================================================================\n",
      "üß† –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ SPT –æ—Ç 10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SPT trees: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 2432.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì SPT –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã\n",
      "\n",
      "üîç –†–∞—Å—á—ë—Ç –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ 372 —Ä—ë–±–µ—Ä...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edges:   5%|‚ñç         | 17/372 [00:02<00:58,  6.10it/s]\n"
     ]
    },
    {
     "ename": "NetworkXError",
     "evalue": "The edge 245918989-272608964 is not in the graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/networkx/classes/multidigraph.py:583\u001b[39m, in \u001b[36mMultiDiGraph.remove_edge\u001b[39m\u001b[34m(self, u, v, key)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     d = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mKeyError\u001b[39m: 272608964",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNetworkXError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m results = \u001b[43mmain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGRAPH_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müéâ –í–°–ï –ì–û–¢–û–í–û!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 456\u001b[39m, in \u001b[36mmain_pipeline\u001b[39m\u001b[34m(graph_name, data_dir, output_dir)\u001b[39m\n\u001b[32m    454\u001b[39m criticality_file = os.path.join(graph_output_dir, \u001b[33m'\u001b[39m\u001b[33mcriticality_scores.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(criticality_file):\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     crit_df = \u001b[43mcalculate_edge_criticality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mod_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriticality_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úì –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcriticality_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, –∑–∞–≥—Ä—É–∂–∞—é...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mcalculate_edge_criticality\u001b[39m\u001b[34m(graph, od_pairs_df, demand_dict, output_file, checkpoint_interval)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# –ø–µ—Ä–µ—Å—á—ë—Ç d_new\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# –£–±–∏—Ä–∞–µ–º —Ä–µ–±—Ä–æ (–±—ã—Å—Ç—Ä–µ–µ, —á–µ–º –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ!)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_edge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     d_new = nx.shortest_path_length(graph, s, t, weight=\u001b[33m\"\u001b[39m\u001b[33mtravel_time\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    143\u001b[39m     graph.add_edge(u, v, key)  \u001b[38;5;66;03m# –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/networkx/classes/multidigraph.py:585\u001b[39m, in \u001b[36mMultiDiGraph.remove_edge\u001b[39m\u001b[34m(self, u, v, key)\u001b[39m\n\u001b[32m    583\u001b[39m     d = \u001b[38;5;28mself\u001b[39m._adj[u][v]\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NetworkXError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe edge \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mu\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not in the graph.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    586\u001b[39m \u001b[38;5;66;03m# remove the edge with specified data\u001b[39;00m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNetworkXError\u001b[39m: The edge 245918989-272608964 is not in the graph."
     ]
    }
   ],
   "source": [
    "\n",
    "# –ó–ê–ü–£–°–ö\n",
    "\n",
    "# 'zmr' - —Å–∞–º—ã–π –º–∞–ª–µ–Ω—å–∫–∏–π, –±—ã—Å—Ç—Ä—ã–π (~10-20 –º–∏–Ω—É—Ç)\n",
    "# 'sao' - —Å—Ä–µ–¥–Ω–∏–π (~1-3 —á–∞—Å–∞)\n",
    "# 'moscow' - –±–æ–ª—å—à–æ–π (~10-20 —á–∞—Å–æ–≤)\n",
    "\n",
    "GRAPH_NAME = 'zmr'\n",
    "DATA_DIR = 'map_data'\n",
    "OUTPUT_DIR = 'results'\n",
    "\n",
    "print(\"\\nüéØ –í—ã–±—Ä–∞–Ω –≥—Ä–∞—Ñ:\", GRAPH_NAME.upper())\n",
    "print(\"üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏:\", DATA_DIR)\n",
    "print(\"üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\", OUTPUT_DIR)\n",
    "print()\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
    "results = main_pipeline(GRAPH_NAME, DATA_DIR, OUTPUT_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ –í–°–ï –ì–û–¢–û–í–û!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤: {OUTPUT_DIR}/{GRAPH_NAME}/\")\n",
    "print(f\"   - percolation_results.csv  (–≤—Å–µ –¥–∞–Ω–Ω—ã–µ)\")\n",
    "print(f\"   - percolation_plot.png     (–≥—Ä–∞—Ñ–∏–∫–∏)\")\n",
    "print(f\"   - initial_distances.csv    (–∏—Å—Ö–æ–¥–Ω—ã–µ –ø—É—Ç–∏)\")\n",
    "print(f\"   - criticality_scores.csv   (–∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–±–µ—Ä)\")\n",
    "print(f\"   - summary.txt              (–∫—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)\")\n",
    "\n",
    "# –ü—Ä–µ–≤—å—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(\"\\nüìà –ü—Ä–µ–≤—å—é —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\")\n",
    "print(results.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ map_data/zmr.pkl...\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: 178 —É–∑–ª–æ–≤, 372 —Ä—ë–±–µ—Ä\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ map_data/sao.pkl...\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: 1587 —É–∑–ª–æ–≤, 3318 —Ä—ë–±–µ—Ä\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ map_data/moscow.pkl...\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: 26955 —É–∑–ª–æ–≤, 58206 —Ä—ë–±–µ—Ä\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'map_data'\n",
    "\n",
    "Gs = {\n",
    "\t'zmr': load_graph_pickle(os.path.join(data_dir, f'zmr.pkl')),\n",
    "\t'sao': load_graph_pickle(os.path.join(data_dir, f'sao.pkl')),\n",
    "\t'moscow': load_graph_pickle(os.path.join(data_dir, f'moscow.pkl'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def choose_od():\n",
    "# \tmoscow_center = (55.7558, 37.6173)\n",
    "\n",
    "# \tfor name, G in Gs.items():\n",
    "# \t\tprint(f\"{name}:\")\n",
    "\n",
    "# \t\tif name == 'moscow':\n",
    "# \t\t\tcenter_radius = 8000\n",
    "# \t\telif name == 'sao':\n",
    "# \t\t\tcenter_radius = 10000\n",
    "# \t\telif name == 'zmr':\n",
    "# \t\t\tcenter_radius = 2000\n",
    "\n",
    "# \t\tcenter_nodes = []\n",
    "# \t\tperiphery_nodes = []\n",
    "\n",
    "# \t\tfor node in G.nodes():\n",
    "# \t\t\t\tlat = G.nodes[node]['y']\n",
    "# \t\t\t\tlon = G.nodes[node]['x']\n",
    "# \t\t\t\tdist = geodesic(moscow_center, (lat, lon)).meters\n",
    "\n",
    "# \t\t\t\tif dist < center_radius:\n",
    "# \t\t\t\t\t\tcenter_nodes.append(node)\n",
    "# \t\t\t\telse:\n",
    "# \t\t\t\t\t\tperiphery_nodes.append(node)\n",
    "\n",
    "# \t\tprint(f\"–£–∑–ª–æ–≤ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º —Ä–∞–π–æ–Ω–µ: {len(center_nodes)}\")\n",
    "# \t\tprint(f\"–£–∑–ª–æ–≤ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏: {len(periphery_nodes)}\")\n",
    "\n",
    "# \t\tnp.random.seed(1984)\n",
    "# \t\tn_center = min(10, len(center_nodes))\n",
    "# \t\tn_periphery = min(5000, len(periphery_nodes))\n",
    "\n",
    "# \t\tcenter_sample = np.random.choice(center_nodes, n_center, replace=False)\n",
    "# \t\tperiphery_sample = np.random.choice(periphery_nodes, n_periphery, replace=False)\n",
    "\n",
    "# \t\tprint(f\"–í—ã–±—Ä–∞–Ω–æ –¥–ª—è O-D –ø–∞—Ä:\")\n",
    "# \t\tprint(f\"    –í —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º —Ä–∞–π–æ–Ω–µ: {n_center}\")\n",
    "# \t\tprint(f\"    –ù–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏: {n_periphery}\")\n",
    "\n",
    "# \t\tprint(f\"–°–æ–∑–¥–∞–Ω–∏–µ O-D –ø–∞—Ä...\")\n",
    "\n",
    "# \t\tod_pairs = []\n",
    "# \t\tfor _ in range(5000):\n",
    "# \t\t\t\torigin = np.random.choice(center_sample)\n",
    "# \t\t\t\tdestination = np.random.choice(periphery_sample)\n",
    "# \t\t\t\tif origin != destination:\n",
    "# \t\t\t\t\t\tod_pairs.append({\n",
    "# \t\t\t\t\t\t\t\t'node_id_origin': origin,\n",
    "# \t\t\t\t\t\t\t\t'node_id_dest': destination\n",
    "# \t\t\t\t\t\t})\n",
    "\n",
    "# \t\tdf_od = pd.DataFrame(od_pairs)\n",
    "# \t\tprint(f\"–°–æ–∑–¥–∞–Ω–æ {len(df_od)} O-D –ø–∞—Ä\")\n",
    "# \t\tdf_od.to_csv(f\"./map_data/{name}_od_pairs.csv\")\n",
    "# \t\tprint(f\"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ ./map_data/{name}_od_pairs.csv\")\n",
    "\n",
    "# \t\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: (55.7342723, 37.6277463) End: (55.7348074, 37.6277767)\n"
     ]
    }
   ],
   "source": [
    "crit_scores = pd.read_csv('./results/zmr/criticality_scores.csv')\n",
    "crit_score1 = crit_scores.iloc[0]\n",
    "edge_data = Gs['zmr'][crit_score1['edge_u']][crit_score1['edge_v']][crit_score1['edge_key']]\n",
    "\n",
    "if 'geometry' in edge_data:\n",
    "    line = edge_data['geometry']  # shapely LineString\n",
    "    start_coord = line.coords[0]\n",
    "    start_coord = start_coord[1], start_coord[0]   # –ø–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞\n",
    "    end_coord = line.coords[-1]\n",
    "    end_coord = end_coord[1], end_coord[0]   # –ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞\n",
    "# else:\n",
    "#     # –ï—Å–ª–∏ geometry –Ω–µ—Ç, –±–µ—Ä–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–µ—Ä—à–∏–Ω\n",
    "#     start_coord = (G.nodes[u]['y'], G.nodes[u]['x'])  # OSMnx –∏—Å–ø–æ–ª—å–∑—É–µ—Ç y=lat, x=lon\n",
    "#     end_coord = (G.nodes[v]['y'], G.nodes[v]['x'])\n",
    "\n",
    "print(\"Start:\", start_coord, \"End:\", end_coord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
