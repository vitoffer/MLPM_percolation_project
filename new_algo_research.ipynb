{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ –í—ã–±—Ä–∞–Ω –≥—Ä–∞—Ñ: ZMR\n",
      "üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏: map_data\n",
      "üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: results\n",
      "\n",
      "================================================================================\n",
      "üöÄ –°–¢–ê–†–¢ –ê–ù–ê–õ–ò–ó–ê –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–û–ô –£–°–¢–û–ô–ß–ò–í–û–°–¢–ò: ZMR\n",
      "================================================================================\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ map_data/zmr.pkl...\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: 178 —É–∑–ª–æ–≤, 372 —Ä—ë–±–µ—Ä\n",
      "\n",
      "‚úì –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π results/zmr/initial_distances.csv, –∑–∞–≥—Ä—É–∂–∞—é...\n",
      "   –ó–∞–≥—Ä—É–∂–µ–Ω–æ 5000 O-D –ø–∞—Ä\n",
      "\n",
      "‚úì –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π results/zmr/criticality_scores.csv, –∑–∞–≥—Ä—É–∂–∞—é...\n",
      "   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–µ–π –¥–ª—è 372 —Ä–µ–±–µ—Ä\n",
      "\n",
      "================================================================================\n",
      "üéØ –®–ê–ì 3: –°–ò–ú–£–õ–Ø–¶–ò–Ø –¶–ï–õ–ï–í–û–ô –ê–¢–ê–ö–ò\n",
      "================================================================================\n",
      "üìä –†–∞—Å—á–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫...\n",
      "   –ò—Å—Ö–æ–¥–Ω–∞—è LCC: 1.0000\n",
      "   –ò—Å—Ö–æ–¥–Ω–∞—è Efficiency: 0.249481\n",
      "\n",
      "üî® –ù–∞—á–∏–Ω–∞—é —É–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–±–µ—Ä –ø–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏...\n",
      "   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: 20\n",
      "   –†–µ–±–µ—Ä –Ω–∞ —à–∞–≥: ~18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–¶–µ–ª–µ–≤–∞—è –∞—Ç–∞–∫–∞: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 78.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   –®–∞–≥ 5/20 (25%): LCC=0.6180, Eff=0.084265\n",
      "   –®–∞–≥ 10/20 (50%): LCC=0.4438, Eff=0.046221\n",
      "   –®–∞–≥ 15/20 (75%): LCC=0.1685, Eff=0.017600\n",
      "   –®–∞–≥ 20/20 (100%): LCC=0.0225, Eff=0.000061\n",
      "\n",
      "‚úÖ –¶–µ–ª–µ–≤–∞—è –∞—Ç–∞–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n",
      "\n",
      "================================================================================\n",
      "üé≤ –®–ê–ì 4: –°–ò–ú–£–õ–Ø–¶–ò–Ø –°–õ–£–ß–ê–ô–ù–û–ì–û –û–¢–ö–ê–ó–ê\n",
      "================================================================================\n",
      "   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–æ–Ω–æ–≤: 50\n",
      "   –®–∞–≥–æ–≤ –Ω–∞ –ø—Ä–æ–≥–æ–Ω: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥–æ–Ω—ã: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:16<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –°–ª—É—á–∞–π–Ω—ã–π –æ—Ç–∫–∞–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –£—Å—Ä–µ–¥–Ω–µ–Ω–æ 50 –ø—Ä–æ–≥–æ–Ω–æ–≤\n",
      "\n",
      "================================================================================\n",
      "üìä –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\n",
      "================================================================================\n",
      "‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/zmr/percolation_results.csv\n",
      "üìÑ –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ results/zmr/summary.txt\n",
      "\n",
      "üìà –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...\n",
      "   ‚úì –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: results/zmr/percolation_plot.png\n",
      "\n",
      "================================================================================\n",
      "‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –î–õ–Ø ZMR!\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üéâ –í–°–ï –ì–û–¢–û–í–û!\n",
      "================================================================================\n",
      "\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤: results/zmr/\n",
      "   - percolation_results.csv  (–≤—Å–µ –¥–∞–Ω–Ω—ã–µ)\n",
      "   - percolation_plot.png     (–≥—Ä–∞—Ñ–∏–∫–∏)\n",
      "   - initial_distances.csv    (–∏—Å—Ö–æ–¥–Ω—ã–µ –ø—É—Ç–∏)\n",
      "   - criticality_scores.csv   (–∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–±–µ—Ä)\n",
      "   - summary.txt              (–∫—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)\n",
      "\n",
      "üìà –ü—Ä–µ–≤—å—é —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\n",
      "   fraction_removed  strategy metric_type     value\n",
      "0              0.00  Targeted         LCC  1.000000\n",
      "1              0.00  Targeted  Efficiency  0.249481\n",
      "2              0.05  Targeted         LCC  0.988764\n",
      "3              0.05  Targeted  Efficiency  0.170541\n",
      "4              0.10  Targeted         LCC  0.685393\n",
      "5              0.10  Targeted  Efficiency  0.144198\n",
      "6              0.15  Targeted         LCC  0.657303\n",
      "7              0.15  Targeted  Efficiency  0.116033\n",
      "8              0.20  Targeted         LCC  0.651685\n",
      "9              0.20  Targeted  Efficiency  0.102823\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ó–ê–ì–†–£–ó–ö–ê –ì–†–ê–§–ê –ò–ó PICKLE\n",
    "\n",
    "def load_graph_pickle(pickle_file):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥—Ä–∞—Ñ –∏–∑ pickle —Ñ–∞–π–ª–∞\"\"\"\n",
    "    print(f\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ {pickle_file}...\")\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        G = pickle.load(f)\n",
    "    print(f\"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {G.number_of_nodes()} —É–∑–ª–æ–≤, {G.number_of_edges()} —Ä—ë–±–µ—Ä\")\n",
    "    return G\n",
    "\n",
    "\n",
    "# 1. –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–´–ô –†–ê–°–ß–ï–¢: –ò—Å—Ö–æ–¥–Ω—ã–µ –∫—Ä–∞—Ç—á–∞–π—à–∏–µ –ø—É—Ç–∏ d_ij\n",
    "\n",
    "def calculate_initial_distances(graph, od_pairs_file, output_file='initial_distances.csv'):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–µ –∫—Ä–∞—Ç—á–∞–π—à–µ–µ –≤—Ä–µ–º—è –≤ –ø—É—Ç–∏ –¥–ª—è –≤—Å–µ—Ö O-D –ø–∞—Ä.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä –®–ê–ì 1: –†–ê–°–ß–ï–¢ –ò–°–•–û–î–ù–´–• –†–ê–°–°–¢–û–Ø–ù–ò–ô\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(f\"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ O-D –ø–∞—Ä –∏–∑ {od_pairs_file}...\")\n",
    "    od_pairs = pd.read_csv(od_pairs_file)\n",
    "\n",
    "    results = []\n",
    "    print(f\"üìê –†–∞—Å—á–µ—Ç –∫—Ä–∞—Ç—á–∞–π—à–∏—Ö –ø—É—Ç–µ–π –¥–ª—è {len(od_pairs)} –ø–∞—Ä...\")\n",
    "\n",
    "    for idx, row in tqdm(od_pairs.iterrows(), total=len(od_pairs), desc=\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä\"):\n",
    "        origin = row['node_id_origin']\n",
    "        dest = row['node_id_dest']\n",
    "\n",
    "        try:\n",
    "            # –ö—Ä–∞—Ç—á–∞–π—à–∏–π –ø—É—Ç—å –ø–æ –≤–µ—Å—É travel_time\n",
    "            distance = nx.shortest_path_length(graph, origin, dest, weight='travel_time')\n",
    "            results.append({\n",
    "                'origin': origin,\n",
    "                'dest': dest,\n",
    "                'distance_original': distance\n",
    "            })\n",
    "        except nx.NetworkXNoPath:\n",
    "            # –ï—Å–ª–∏ –ø—É—Ç–∏ –Ω–µ—Ç, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ = –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å\n",
    "            results.append({\n",
    "                'origin': origin,\n",
    "                'dest': dest,\n",
    "                'distance_original': np.inf\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    valid_distances = df[df['distance_original'] != np.inf]['distance_original']\n",
    "    print(f\"\\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}\")\n",
    "    print(f\"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "    print(f\"   - –í—Å–µ–≥–æ –ø–∞—Ä: {len(df)}\")\n",
    "    print(f\"   - –°–≤—è–∑–Ω—ã—Ö –ø–∞—Ä: {len(valid_distances)}\")\n",
    "    print(f\"   - –ù–µ—Å–≤—è–∑–Ω—ã—Ö –ø–∞—Ä: {len(df) - len(valid_distances)}\")\n",
    "    print(f\"   - –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {valid_distances.mean():.2f} –º–∏–Ω\")\n",
    "    print(f\"   - –ú–µ–¥–∏–∞–Ω–∞: {valid_distances.median():.2f} –º–∏–Ω\")\n",
    "    print(f\"   - –ú–∞–∫—Å: {valid_distances.max():.2f} –º–∏–Ω\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 2. –†–ê–°–ß–ï–¢ –ö–†–ò–¢–ò–ß–ù–û–°–¢–ò –†–ï–ë–†–ê (W_e) - STRETCH FACTOR\n",
    "\n",
    "def calculate_edge_criticality(graph, od_pairs_df, demand_dict=None,\n",
    "                               output_file='criticality_scores.csv',\n",
    "                               checkpoint_interval=100):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —Ä–µ–±—Ä–∞ (W_e) –ø–æ —Ñ–æ—Ä–º—É–ª–µ Stretch Factor.\n",
    "\n",
    "    W_e = Œ£ max(0, (d_new - d_orig) / d_orig) √ó Demand_ij\n",
    "\n",
    "    od_pairs_df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ origin, dest, distance_original\n",
    "    demand_dict: —Å–ª–æ–≤–∞—Ä—å {(origin, dest): —Å–ø—Ä–æ—Å}, –µ—Å–ª–∏ None - –≤—Å–µ —Å–ø—Ä–æ—Å—ã = 1\n",
    "    checkpoint_interval: –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîç –®–ê–ì 2: –†–ê–°–ß–ï–¢ –ö–†–ò–¢–ò–ß–ù–û–°–¢–ò –†–ï–ë–ï–† (W_e)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ —Å–∞–º–∞—è –¥–æ–ª–≥–∞—è —á–∞—Å—Ç—å!\")\n",
    "    print(\"‚è±Ô∏è  –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è:\")\n",
    "    print(\"   - –ú–∞–ª—ã–π –≥—Ä–∞—Ñ (~200 —Ä—ë–±–µ—Ä): ~5-10 –º–∏–Ω—É—Ç\")\n",
    "    print(\"   - –°—Ä–µ–¥–Ω–∏–π –≥—Ä–∞—Ñ (~3000 —Ä—ë–±–µ—Ä): ~1-2 —á–∞—Å–∞\")\n",
    "    print(\"   - –ë–æ–ª—å—à–æ–π –≥—Ä–∞—Ñ (~60000 —Ä—ë–±–µ—Ä): ~10-20 —á–∞—Å–æ–≤\")\n",
    "    print()\n",
    "\n",
    "    edges = list(graph.edges(keys=True))\n",
    "    criticality_scores = []\n",
    "\n",
    "    # –ï—Å–ª–∏ —Å–ø—Ä–æ—Å –Ω–µ –∑–∞–¥–∞–Ω, –≤—Å–µ –ø–∞—Ä—ã –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å–ø—Ä–æ—Å = 1\n",
    "    if demand_dict is None:\n",
    "        demand_dict = {(row['origin'], row['dest']): 1\n",
    "                       for _, row in od_pairs_df.iterrows()}\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–≤—è–∑–Ω—ã–µ –ø–∞—Ä—ã\n",
    "    valid_od_pairs = od_pairs_df[od_pairs_df['distance_original'] != np.inf]\n",
    "    print(f\"üì¶ –í—Å–µ–≥–æ —Ä–µ–±–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(edges)}\")\n",
    "    print(f\"üìç –í–∞–ª–∏–¥–Ω—ã—Ö O-D –ø–∞—Ä: {len(valid_od_pairs)}/{len(od_pairs_df)}\")\n",
    "    print()\n",
    "\n",
    "    for edge_idx, (u, v, key) in enumerate(tqdm(edges, desc=\"–ê–Ω–∞–ª–∏–∑ —Ä–µ–±–µ—Ä\")):\n",
    "        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é –≥—Ä–∞—Ñ–∞ –±–µ–∑ —ç—Ç–æ–≥–æ —Ä–µ–±—Ä–∞\n",
    "        G_temp = graph.copy()\n",
    "        G_temp.remove_edge(u, v, key)\n",
    "\n",
    "        total_stretch = 0\n",
    "\n",
    "        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –≤–∞–ª–∏–¥–Ω—ã–º O-D –ø–∞—Ä–∞–º\n",
    "        for _, row in valid_od_pairs.iterrows():\n",
    "            origin = row['origin']\n",
    "            dest = row['dest']\n",
    "            d_original = row['distance_original']\n",
    "\n",
    "            try:\n",
    "                # –ù–æ–≤–æ–µ –∫—Ä–∞—Ç—á–∞–π—à–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –±–µ–∑ —Ä–µ–±—Ä–∞ e\n",
    "                d_new = nx.shortest_path_length(G_temp, origin, dest, weight='travel_time')\n",
    "\n",
    "                # Stretch Factor: –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—É—Ç–∏\n",
    "                stretch = max(0, (d_new - d_original) / d_original)\n",
    "\n",
    "                # –£–º–Ω–æ–∂–∞–µ–º –Ω–∞ —Å–ø—Ä–æ—Å\n",
    "                demand = demand_dict.get((origin, dest), 1)\n",
    "                total_stretch += stretch * demand\n",
    "\n",
    "            except nx.NetworkXNoPath:\n",
    "                # –ï—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–±—Ä–∞ —Ä–∞–∑–æ—Ä–≤–∞–ª–æ –ø—É—Ç—å - –±–æ–ª—å—à–æ–π —à—Ç—Ä–∞—Ñ\n",
    "                demand = demand_dict.get((origin, dest), 1)\n",
    "                total_stretch += 10.0 * demand\n",
    "\n",
    "        criticality_scores.append({\n",
    "            'edge_u': u,\n",
    "            'edge_v': v,\n",
    "            'edge_key': key,\n",
    "            'W_e': total_stretch\n",
    "        })\n",
    "\n",
    "        # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "        if (edge_idx + 1) % checkpoint_interval == 0:\n",
    "            temp_df = pd.DataFrame(criticality_scores)\n",
    "            temp_file = f'checkpoint_{output_file}'\n",
    "            d1 = './checkpoint_results/zmr'\n",
    "            d2 = './checkpoint_results/sao'\n",
    "            d3 = './checkpoint_results/moscow'\n",
    "            if not os.path.exists(d1):\n",
    "                os.makedirs(d1)\n",
    "            if not os.path.exists(d2):\n",
    "                os.makedirs(d2)\n",
    "            if not os.path.exists(d3):\n",
    "                os.makedirs(d3)\n",
    "            temp_df.to_csv(temp_file, index=False)\n",
    "            print(f\"\\nüíæ Checkpoint: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(temp_df)} —Ä–µ–±–µ—Ä –≤ {temp_file}\")\n",
    "\n",
    "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏\n",
    "    df = pd.DataFrame(criticality_scores)\n",
    "    df = df.sort_values('W_e', ascending=False).reset_index(drop=True)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ –ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–±–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {output_file}\")\n",
    "    print(f\"\\nüîù –¢–æ–ø-10 —Å–∞–º—ã—Ö –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ä–µ–±–µ—Ä:\")\n",
    "    print(df.head(10).to_string())\n",
    "    print(f\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ W_e:\")\n",
    "    print(f\"   - –°—Ä–µ–¥–Ω–µ–µ: {df['W_e'].mean():.4f}\")\n",
    "    print(f\"   - –ú–µ–¥–∏–∞–Ω–∞: {df['W_e'].median():.4f}\")\n",
    "    print(f\"   - –ú–∞–∫—Å: {df['W_e'].max():.4f}\")\n",
    "    print(f\"   - –ú–∏–Ω: {df['W_e'].min():.4f}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 3. –ú–ï–¢–†–ò–ö–ò: LCC –∏ GLOBAL EFFICIENCY\n",
    "\n",
    "def calculate_lcc(graph):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∫—Ä—É–ø–Ω–µ–π—à–µ–π —Å–≤—è–∑–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (LCC).\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–ª—é —É–∑–ª–æ–≤ –≤ LCC –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ —É–∑–ª–æ–≤.\n",
    "    \"\"\"\n",
    "    if graph.number_of_nodes() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # –î–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º weakly connected\n",
    "    if graph.is_directed():\n",
    "        largest_cc = max(nx.weakly_connected_components(graph), key=len)\n",
    "    else:\n",
    "        largest_cc = max(nx.connected_components(graph), key=len)\n",
    "\n",
    "    return len(largest_cc) / graph.number_of_nodes()\n",
    "\n",
    "\n",
    "def calculate_global_efficiency(graph, sample_size=None):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (E).\n",
    "\n",
    "    E = 1 / (N*(N-1)) * Œ£ (1 / d_ij)\n",
    "\n",
    "    Args:\n",
    "        graph: NetworkX –≥—Ä–∞—Ñ\n",
    "        sample_size: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—ã–±–æ—Ä–∫—É —É–∑–ª–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "    \"\"\"\n",
    "    nodes = list(graph.nodes())\n",
    "    N = len(nodes)\n",
    "\n",
    "    if N <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    # –î–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä–∞—Ñ–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±–æ—Ä–∫—É\n",
    "    if sample_size and N > sample_size:\n",
    "        nodes = np.random.choice(nodes, sample_size, replace=False)\n",
    "        N = len(nodes)\n",
    "\n",
    "    total_inv_distance = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        # –ö—Ä–∞—Ç—á–∞–π—à–∏–µ –ø—É—Ç–∏ –æ—Ç —É–∑–ª–∞ i –∫–æ –≤—Å–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–º\n",
    "        try:\n",
    "            lengths = nx.single_source_dijkstra_path_length(\n",
    "                graph, nodes[i], weight='travel_time'\n",
    "            )\n",
    "\n",
    "            for j in range(i + 1, N):\n",
    "                if nodes[j] in lengths:\n",
    "                    d_ij = lengths[nodes[j]]\n",
    "                    if d_ij > 0:\n",
    "                        total_inv_distance += 1.0 / d_ij\n",
    "                        count += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if count == 0:\n",
    "        return 0.0\n",
    "\n",
    "    efficiency = total_inv_distance / (N * (N - 1))\n",
    "    return efficiency\n",
    "\n",
    "\n",
    "# 4. –°–ò–ú–£–õ–Ø–¶–ò–Ø: –¶–ï–õ–ï–í–ê–Ø –ê–¢–ê–ö–ê (Targeted Attack)\n",
    "\n",
    "def simulate_targeted_attack(graph, criticality_df, steps=20, efficiency_sample=500):\n",
    "    \"\"\"\n",
    "    –°–∏–º—É–ª–∏—Ä—É–µ—Ç —Ü–µ–ª–µ–≤—É—é –∞—Ç–∞–∫—É: —É–¥–∞–ª—è–µ—Ç —Ä–µ–±—Ä–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "    Args:\n",
    "        graph: –∏—Å—Ö–æ–¥–Ω—ã–π –≥—Ä–∞—Ñ\n",
    "        criticality_df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ edge_u, edge_v, edge_key, W_e\n",
    "        steps: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (–ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–∏—è)\n",
    "        efficiency_sample: —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ Efficiency\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ –®–ê–ì 3: –°–ò–ú–£–õ–Ø–¶–ò–Ø –¶–ï–õ–ï–í–û–ô –ê–¢–ê–ö–ò\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    G = graph.copy()\n",
    "    total_edges = G.number_of_edges()\n",
    "    edges_to_remove = criticality_df[['edge_u', 'edge_v', 'edge_key']].values\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
    "    print(\"üìä –†–∞—Å—á–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫...\")\n",
    "    lcc_0 = calculate_lcc(G)\n",
    "    eff_0 = calculate_global_efficiency(G, sample_size=efficiency_sample)\n",
    "    results.append({\n",
    "        'fraction_removed': 0.0,\n",
    "        'strategy': 'Targeted',\n",
    "        'metric_type': 'LCC',\n",
    "        'value': lcc_0\n",
    "    })\n",
    "    results.append({\n",
    "        'fraction_removed': 0.0,\n",
    "        'strategy': 'Targeted',\n",
    "        'metric_type': 'Efficiency',\n",
    "        'value': eff_0\n",
    "    })\n",
    "\n",
    "    print(f\"   –ò—Å—Ö–æ–¥–Ω–∞—è LCC: {lcc_0:.4f}\")\n",
    "    print(f\"   –ò—Å—Ö–æ–¥–Ω–∞—è Efficiency: {eff_0:.6f}\")\n",
    "    print(f\"\\nüî® –ù–∞—á–∏–Ω–∞—é —É–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–±–µ—Ä –ø–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏...\")\n",
    "    print(f\"   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {steps}\")\n",
    "    print(f\"   –†–µ–±–µ—Ä –Ω–∞ —à–∞–≥: ~{total_edges // steps}\")\n",
    "\n",
    "    # –£–¥–∞–ª—è–µ–º —Ä–µ–±—Ä–∞ —à–∞–≥–∞–º–∏\n",
    "    step_size = len(edges_to_remove) // steps\n",
    "\n",
    "    for step in tqdm(range(1, steps + 1), desc=\"–¶–µ–ª–µ–≤–∞—è –∞—Ç–∞–∫–∞\"):\n",
    "        # –£–¥–∞–ª—è–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø–æ—Ä—Ü–∏—é —Ä–µ–±–µ—Ä\n",
    "        start_idx = (step - 1) * step_size\n",
    "        end_idx = min(step * step_size, len(edges_to_remove))\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            u, v, key = edges_to_remove[i]\n",
    "            if G.has_edge(u, v, key):\n",
    "                G.remove_edge(u, v, key)\n",
    "\n",
    "        fraction = step / steps\n",
    "\n",
    "        # –ò–∑–º–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        lcc = calculate_lcc(G)\n",
    "        eff = calculate_global_efficiency(G, sample_size=efficiency_sample)\n",
    "\n",
    "        results.append({\n",
    "            'fraction_removed': fraction,\n",
    "            'strategy': 'Targeted',\n",
    "            'metric_type': 'LCC',\n",
    "            'value': lcc\n",
    "        })\n",
    "        results.append({\n",
    "            'fraction_removed': fraction,\n",
    "            'strategy': 'Targeted',\n",
    "            'metric_type': 'Efficiency',\n",
    "            'value': eff\n",
    "        })\n",
    "\n",
    "        if step % 5 == 0 or step == steps:\n",
    "            print(f\"   –®–∞–≥ {step}/{steps} ({fraction*100:.0f}%): LCC={lcc:.4f}, Eff={eff:.6f}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ –¶–µ–ª–µ–≤–∞—è –∞—Ç–∞–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# 5. –°–ò–ú–£–õ–Ø–¶–ò–Ø: –°–õ–£–ß–ê–ô–ù–´–ô –û–¢–ö–ê–ó (Random Failure)\n",
    "\n",
    "def simulate_random_failure(graph, steps=20, runs=50, efficiency_sample=500):\n",
    "    \"\"\"\n",
    "    –°–∏–º—É–ª–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –æ—Ç–∫–∞–∑: —É–¥–∞–ª—è–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ —Ä–µ–±—Ä–∞.\n",
    "    –ü–æ–≤—Ç–æ—Ä—è–µ—Ç runs —Ä–∞–∑ –∏ —É—Å—Ä–µ–¥–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
    "\n",
    "    Args:\n",
    "        graph: –∏—Å—Ö–æ–¥–Ω—ã–π –≥—Ä–∞—Ñ\n",
    "        steps: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (–ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–∏—è)\n",
    "        runs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è\n",
    "        efficiency_sample: —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ Efficiency\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üé≤ –®–ê–ì 4: –°–ò–ú–£–õ–Ø–¶–ò–Ø –°–õ–£–ß–ê–ô–ù–û–ì–û –û–¢–ö–ê–ó–ê\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–æ–Ω–æ–≤: {runs}\")\n",
    "    print(f\"   –®–∞–≥–æ–≤ –Ω–∞ –ø—Ä–æ–≥–æ–Ω: {steps}\")\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for run in tqdm(range(runs), desc=\"–ü—Ä–æ–≥–æ–Ω—ã\"):\n",
    "        G = graph.copy()\n",
    "        total_edges = G.number_of_edges()\n",
    "        all_edges = list(G.edges(keys=True))\n",
    "\n",
    "        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Ä–µ–±—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º\n",
    "        np.random.shuffle(all_edges)\n",
    "\n",
    "        run_results = []\n",
    "\n",
    "        # –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
    "        lcc_0 = calculate_lcc(G)\n",
    "        eff_0 = calculate_global_efficiency(G, sample_size=efficiency_sample)\n",
    "        run_results.append({\n",
    "            'fraction_removed': 0.0,\n",
    "            'run': run,\n",
    "            'LCC': lcc_0,\n",
    "            'Efficiency': eff_0\n",
    "        })\n",
    "\n",
    "        # –£–¥–∞–ª—è–µ–º —Ä–µ–±—Ä–∞ —à–∞–≥–∞–º–∏\n",
    "        step_size = total_edges // steps\n",
    "\n",
    "        for step in range(1, steps + 1):\n",
    "            start_idx = (step - 1) * step_size\n",
    "            end_idx = min(step * step_size, len(all_edges))\n",
    "\n",
    "            for i in range(start_idx, end_idx):\n",
    "                u, v, key = all_edges[i]\n",
    "                if G.has_edge(u, v, key):\n",
    "                    G.remove_edge(u, v, key)\n",
    "\n",
    "            fraction = step / steps\n",
    "            lcc = calculate_lcc(G)\n",
    "            eff = calculate_global_efficiency(G, sample_size=efficiency_sample)\n",
    "\n",
    "            run_results.append({\n",
    "                'fraction_removed': fraction,\n",
    "                'run': run,\n",
    "                'LCC': lcc,\n",
    "                'Efficiency': eff\n",
    "            })\n",
    "\n",
    "        all_results.extend(run_results)\n",
    "\n",
    "    # –£—Å—Ä–µ–¥–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –≤—Å–µ–º –ø—Ä–æ–≥–æ–Ω–∞–º\n",
    "    df_all = pd.DataFrame(all_results)\n",
    "    df_avg = df_all.groupby('fraction_removed').agg({\n",
    "        'LCC': 'mean',\n",
    "        'Efficiency': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç\n",
    "    results = []\n",
    "    for _, row in df_avg.iterrows():\n",
    "        results.append({\n",
    "            'fraction_removed': row['fraction_removed'],\n",
    "            'strategy': 'Random',\n",
    "            'metric_type': 'LCC',\n",
    "            'value': row['LCC']\n",
    "        })\n",
    "        results.append({\n",
    "            'fraction_removed': row['fraction_removed'],\n",
    "            'strategy': 'Random',\n",
    "            'metric_type': 'Efficiency',\n",
    "            'value': row['Efficiency']\n",
    "        })\n",
    "\n",
    "    print(f\"\\n‚úÖ –°–ª—É—á–∞–π–Ω—ã–π –æ—Ç–∫–∞–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –£—Å—Ä–µ–¥–Ω–µ–Ω–æ {runs} –ø—Ä–æ–≥–æ–Ω–æ–≤\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# 6. –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ü–û–õ–ù–´–ô –ü–ê–ô–ü–õ–ê–ô–ù\n",
    "\n",
    "def main_pipeline(graph_name='zmr', data_dir='map_data', output_dir='results'):\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–∫–æ–ª—è—Ü–∏–∏.\n",
    "\n",
    "    Args:\n",
    "        graph_name: –∏–º—è –≥—Ä–∞—Ñ–∞ ('moscow', 'sao', 'zmr')\n",
    "        data_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç –û–ª–µ–≥–∞\n",
    "        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üöÄ –°–¢–ê–†–¢ –ê–ù–ê–õ–ò–ó–ê –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–û–ô –£–°–¢–û–ô–ß–ò–í–û–°–¢–ò: {graph_name.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º\n",
    "    graph_file = os.path.join(data_dir, f'{graph_name}.pkl')\n",
    "    od_pairs_file = os.path.join(data_dir, f'{graph_name}_od_pairs.csv')\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞\n",
    "    G = load_graph_pickle(graph_file)\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç—Ç–æ–≥–æ –≥—Ä–∞—Ñ–∞\n",
    "    graph_output_dir = os.path.join(output_dir, graph_name)\n",
    "    os.makedirs(graph_output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. –ò—Å—Ö–æ–¥–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è\n",
    "    initial_dist_file = os.path.join(graph_output_dir, 'initial_distances.csv')\n",
    "    if not os.path.exists(initial_dist_file):\n",
    "        od_df = calculate_initial_distances(G, od_pairs_file, initial_dist_file)\n",
    "    else:\n",
    "        print(f\"\\n‚úì –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π {initial_dist_file}, –∑–∞–≥—Ä—É–∂–∞—é...\")\n",
    "        od_df = pd.read_csv(initial_dist_file)\n",
    "        print(f\"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(od_df)} O-D –ø–∞—Ä\")\n",
    "\n",
    "    # 2. –ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–±–µ—Ä\n",
    "    criticality_file = os.path.join(graph_output_dir, 'criticality_scores.csv')\n",
    "    if not os.path.exists(criticality_file):\n",
    "        crit_df = calculate_edge_criticality(G, od_df, output_file=criticality_file)\n",
    "    else:\n",
    "        print(f\"\\n‚úì –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π {criticality_file}, –∑–∞–≥—Ä—É–∂–∞—é...\")\n",
    "        crit_df = pd.read_csv(criticality_file)\n",
    "        print(f\"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–µ–π –¥–ª—è {len(crit_df)} —Ä–µ–±–µ—Ä\")\n",
    "\n",
    "    # 3. –¶–µ–ª–µ–≤–∞—è –∞—Ç–∞–∫–∞\n",
    "    results_targeted = simulate_targeted_attack(G, crit_df, steps=20, efficiency_sample=500)\n",
    "\n",
    "    # 4. –°–ª—É—á–∞–π–Ω—ã–π –æ—Ç–∫–∞–∑\n",
    "    results_random = simulate_random_failure(G, steps=20, runs=50, efficiency_sample=500)\n",
    "\n",
    "    # 5. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\")\n",
    "    print(\"=\"*80)\n",
    "    final_results = pd.concat([results_targeted, results_random], ignore_index=True)\n",
    "\n",
    "    output_file = os.path.join(graph_output_dir, 'percolation_results.csv')\n",
    "    final_results.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}\")\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "    stats_file = os.path.join(graph_output_dir, 'summary.txt')\n",
    "    with open(stats_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"–ì—Ä–∞—Ñ: {graph_name}\\n\")\n",
    "        f.write(f\"–£–∑–ª–æ–≤: {G.number_of_nodes()}\\n\")\n",
    "        f.write(f\"–†–µ–±–µ—Ä: {G.number_of_edges()}\\n\")\n",
    "        f.write(f\"O-D –ø–∞—Ä: {len(od_df)}\\n\")\n",
    "        f.write(f\"\\n–ò—Å—Ö–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:\\n\")\n",
    "        f.write(f\"LCC: {results_targeted[results_targeted['fraction_removed']==0]['value'].iloc[0]:.4f}\\n\")\n",
    "        f.write(f\"Efficiency: {results_targeted[results_targeted['fraction_removed']==0]['value'].iloc[1]:.6f}\\n\")\n",
    "\n",
    "    print(f\"üìÑ –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {stats_file}\")\n",
    "\n",
    "    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫\n",
    "    plot_results(final_results, graph_output_dir, graph_name)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –î–õ–Ø {graph_name.upper()}!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return final_results\n",
    "\n",
    "\n",
    "# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø\n",
    "\n",
    "def plot_results(results, output_dir, graph_name):\n",
    "    \"\"\"–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –ø–µ—Ä–∫–æ–ª—è—Ü–∏–∏\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(\"\\nüìà –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # LCC\n",
    "    for strategy in ['Targeted', 'Random']:\n",
    "        data = results[(results['strategy'] == strategy) &\n",
    "                      (results['metric_type'] == 'LCC')]\n",
    "        ax1.plot(data['fraction_removed'], data['value'],\n",
    "                marker='o', label=strategy, linewidth=2, markersize=6)\n",
    "\n",
    "    ax1.set_xlabel('–î–æ–ª—è —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ä–µ–±–µ—Ä', fontsize=12)\n",
    "    ax1.set_ylabel('LCC (—Ä–∞–∑–º–µ—Ä –∫—Ä—É–ø–Ω–µ–π—à–µ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)', fontsize=12)\n",
    "    ax1.set_title(f'–ü–µ—Ä–∫–æ–ª—è—Ü–∏—è: LCC ({graph_name})', fontsize=14, weight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(alpha=0.3, linestyle='--')\n",
    "    ax1.set_xlim(-0.05, 1.05)\n",
    "    ax1.set_ylim(-0.05, 1.05)\n",
    "\n",
    "    # Efficiency\n",
    "    for strategy in ['Targeted', 'Random']:\n",
    "        data = results[(results['strategy'] == strategy) &\n",
    "                      (results['metric_type'] == 'Efficiency')]\n",
    "        ax2.plot(data['fraction_removed'], data['value'],\n",
    "                marker='s', label=strategy, linewidth=2, markersize=6)\n",
    "\n",
    "    ax2.set_xlabel('–î–æ–ª—è —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ä–µ–±–µ—Ä', fontsize=12)\n",
    "    ax2.set_ylabel('–ì–ª–æ–±–∞–ª—å–Ω–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (E)', fontsize=12)\n",
    "    ax2.set_title(f'–ü–µ—Ä–∫–æ–ª—è—Ü–∏—è: Efficiency ({graph_name})', fontsize=14, weight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(alpha=0.3, linestyle='--')\n",
    "    ax2.set_xlim(-0.05, 1.05)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_file = os.path.join(output_dir, 'percolation_plot.png')\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   ‚úì –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# –ó–ê–ü–£–°–ö\n",
    "\n",
    "# –í—ã–±–µ—Ä–∏ –≥—Ä–∞—Ñ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
    "# 'zmr' - —Å–∞–º—ã–π –º–∞–ª–µ–Ω—å–∫–∏–π, –±—ã—Å—Ç—Ä—ã–π (~10-20 –º–∏–Ω—É—Ç)\n",
    "# 'sao' - —Å—Ä–µ–¥–Ω–∏–π (~1-3 —á–∞—Å–∞)\n",
    "# 'moscow' - –±–æ–ª—å—à–æ–π (~10-20 —á–∞—Å–æ–≤)\n",
    "\n",
    "GRAPH_NAME = 'zmr'  # –ù–∞—á–Ω–∏ —Å –º–∞–ª–æ–≥–æ!\n",
    "DATA_DIR = 'map_data'\n",
    "OUTPUT_DIR = 'results'\n",
    "\n",
    "print(\"\\nüéØ –í—ã–±—Ä–∞–Ω –≥—Ä–∞—Ñ:\", GRAPH_NAME.upper())\n",
    "print(\"üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏:\", DATA_DIR)\n",
    "print(\"üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\", OUTPUT_DIR)\n",
    "print()\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
    "results = main_pipeline(GRAPH_NAME, DATA_DIR, OUTPUT_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ –í–°–ï –ì–û–¢–û–í–û!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤: {OUTPUT_DIR}/{GRAPH_NAME}/\")\n",
    "print(f\"   - percolation_results.csv  (–≤—Å–µ –¥–∞–Ω–Ω—ã–µ)\")\n",
    "print(f\"   - percolation_plot.png     (–≥—Ä–∞—Ñ–∏–∫–∏)\")\n",
    "print(f\"   - initial_distances.csv    (–∏—Å—Ö–æ–¥–Ω—ã–µ –ø—É—Ç–∏)\")\n",
    "print(f\"   - criticality_scores.csv   (–∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–±–µ—Ä)\")\n",
    "print(f\"   - summary.txt              (–∫—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)\")\n",
    "\n",
    "# –ü—Ä–µ–≤—å—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(\"\\nüìà –ü—Ä–µ–≤—å—é —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\")\n",
    "print(results.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ map_data/zmr.pkl...\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: 178 —É–∑–ª–æ–≤, 372 —Ä—ë–±–µ—Ä\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ map_data/sao.pkl...\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: 1587 —É–∑–ª–æ–≤, 3318 —Ä—ë–±–µ—Ä\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ map_data/moscow.pkl...\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: 26955 —É–∑–ª–æ–≤, 58206 —Ä—ë–±–µ—Ä\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'map_data'\n",
    "\n",
    "Gs = {\n",
    "\t'zmr': load_graph_pickle(os.path.join(data_dir, f'zmr.pkl')),\n",
    "\t'sao': load_graph_pickle(os.path.join(data_dir, f'sao.pkl')),\n",
    "\t'moscow': load_graph_pickle(os.path.join(data_dir, f'moscow.pkl'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_od():\n",
    "\tmoscow_center = (55.7558, 37.6173)\n",
    "\n",
    "\tfor name, G in Gs.items():\n",
    "\t\tprint(f\"{name}:\")\n",
    "\n",
    "\t\tif name == 'moscow':\n",
    "\t\t\tcenter_radius = 8000\n",
    "\t\telif name == 'sao':\n",
    "\t\t\tcenter_radius = 12000\n",
    "\t\telif name == 'zmr':\n",
    "\t\t\tcenter_radius = 2500\n",
    "\n",
    "\t\tcenter_nodes = []\n",
    "\t\tperiphery_nodes = []\n",
    "\n",
    "\t\tfor node in G.nodes():\n",
    "\t\t\t\tlat = G.nodes[node]['y']\n",
    "\t\t\t\tlon = G.nodes[node]['x']\n",
    "\t\t\t\tdist = geodesic(moscow_center, (lat, lon)).meters\n",
    "\n",
    "\t\t\t\tif dist < center_radius:\n",
    "\t\t\t\t\t\tcenter_nodes.append(node)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t\tperiphery_nodes.append(node)\n",
    "\n",
    "\t\tprint(f\"–£–∑–ª–æ–≤ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º —Ä–∞–π–æ–Ω–µ: {len(center_nodes)}\")\n",
    "\t\tprint(f\"–£–∑–ª–æ–≤ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏: {len(periphery_nodes)}\")\n",
    "\n",
    "\t\tnp.random.seed(1984)\n",
    "\t\tn_center = min(10, len(center_nodes))\n",
    "\t\tn_periphery = min(5000, len(periphery_nodes))\n",
    "\n",
    "\t\tcenter_sample = np.random.choice(center_nodes, n_center, replace=False)\n",
    "\t\tperiphery_sample = np.random.choice(periphery_nodes, n_periphery, replace=False)\n",
    "\n",
    "\t\tprint(f\"–í—ã–±—Ä–∞–Ω–æ –¥–ª—è O-D –ø–∞—Ä:\")\n",
    "\t\tprint(f\"    –í —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º —Ä–∞–π–æ–Ω–µ: {n_center}\")\n",
    "\t\tprint(f\"    –ù–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏: {n_periphery}\")\n",
    "\n",
    "\t\tprint(f\"–°–æ–∑–¥–∞–Ω–∏–µ O-D –ø–∞—Ä...\")\n",
    "\n",
    "\t\tod_pairs = []\n",
    "\t\tfor _ in range(5000):\n",
    "\t\t\t\torigin = np.random.choice(center_sample)\n",
    "\t\t\t\tdestination = np.random.choice(periphery_sample)\n",
    "\t\t\t\tif origin != destination:\n",
    "\t\t\t\t\t\tod_pairs.append({\n",
    "\t\t\t\t\t\t\t\t'node_id_origin': origin,\n",
    "\t\t\t\t\t\t\t\t'node_id_dest': destination\n",
    "\t\t\t\t\t\t})\n",
    "\n",
    "\t\tdf_od = pd.DataFrame(od_pairs)\n",
    "\t\tprint(f\"–°–æ–∑–¥–∞–Ω–æ {len(df_od)} O-D –ø–∞—Ä\")\n",
    "\t\tdf_od.to_csv(f\"./map_data/{name}_od_pairs.csv\")\n",
    "\t\tprint(f\"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ ./map_data/{name}_od_pairs.csv\")\n",
    "\n",
    "\t\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: (55.7342723, 37.6277463) End: (55.7348074, 37.6277767)\n"
     ]
    }
   ],
   "source": [
    "crit_scores = pd.read_csv('./results/zmr/criticality_scores.csv')\n",
    "crit_score1 = crit_scores.iloc[0]\n",
    "edge_data = Gs['zmr'][crit_score1['edge_u']][crit_score1['edge_v']][crit_score1['edge_key']]\n",
    "\n",
    "if 'geometry' in edge_data:\n",
    "    line = edge_data['geometry']  # shapely LineString\n",
    "    start_coord = tuple(reversed(list(line.coords[0])))   # –ø–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞\n",
    "    end_coord = tuple(reversed(list(line.coords[-1])))   # –ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞\n",
    "# else:\n",
    "#     # –ï—Å–ª–∏ geometry –Ω–µ—Ç, –±–µ—Ä–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–µ—Ä—à–∏–Ω\n",
    "#     start_coord = (G.nodes[u]['y'], G.nodes[u]['x'])  # OSMnx –∏—Å–ø–æ–ª—å–∑—É–µ—Ç y=lat, x=lon\n",
    "#     end_coord = (G.nodes[v]['y'], G.nodes[v]['x'])\n",
    "\n",
    "print(\"Start:\", start_coord, \"End:\", end_coord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
